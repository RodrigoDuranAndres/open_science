<?xml version="1.0" encoding="UTF-8"?>
<TEI xml:space="preserve" xmlns="http://www.tei-c.org/ns/1.0" 
xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" 
xsi:schemaLocation="http://www.tei-c.org/ns/1.0 https://raw.githubusercontent.com/kermitt2/grobid/master/grobid-home/schemas/xsd/Grobid.xsd"
 xmlns:xlink="http://www.w3.org/1999/xlink">
	<teiHeader xml:lang="en">
		<fileDesc>
			<titleStmt>
				<title level="a" type="main" coord="1,237.63,101.17,136.74,15.48">Mixtral of Experts</title>
			</titleStmt>
			<publicationStmt>
				<publisher/>
				<availability status="unknown"><licence/></availability>
				<date type="published" when="2024-01-08">8 Jan 2024</date>
			</publicationStmt>
			<sourceDesc>
				<biblStruct>
					<analytic>
						<author>
							<persName coords="1,152.55,161.93,64.14,8.96"><forename type="first">Albert</forename><forename type="middle">Q</forename><surname>Jiang</surname></persName>
						</author>
						<author>
							<persName coords="1,223.48,161.93,96.75,8.96"><forename type="first">Alexandre</forename><surname>Sablayrolles</surname></persName>
						</author>
						<author>
							<persName coords="1,326.90,161.93,56.40,8.96"><forename type="first">Antoine</forename><surname>Roux</surname></persName>
						</author>
						<author>
							<persName coords="1,390.83,161.93,63.52,8.96"><forename type="first">Arthur</forename><surname>Mensch</surname></persName>
						</author>
						<author>
							<persName coords="1,140.65,172.84,63.80,8.96"><forename type="first">Blanche</forename><surname>Savary</surname></persName>
						</author>
						<author>
							<persName coords="1,211.43,172.84,61.67,8.96"><forename type="first">Chris</forename><surname>Bamford</surname></persName>
						</author>
						<author>
							<persName coords="1,280.64,172.84,68.11,8.96"><forename type="first">Singh</forename><surname>Devendra</surname></persName>
						</author>
						<author>
							<persName coords="1,351.25,172.84,63.65,8.96"><forename type="first">Diego</forename><surname>Chaplot</surname></persName>
						</author>
						<author>
							<persName coords="1,417.39,172.84,49.40,8.96;1,154.51,183.75,47.88,8.96"><forename type="first">Emma</forename><forename type="middle">Bou</forename><surname>De Las Casas</surname></persName>
						</author>
						<author>
							<persName coords="1,204.88,183.75,65.33,8.96"><forename type="first">Florian</forename><surname>Hanna</surname></persName>
						</author>
						<author>
							<persName coords="1,272.69,183.75,75.67,8.96"><forename type="first">Gianna</forename><surname>Bressand</surname></persName>
						</author>
						<author>
							<persName coords="1,350.85,183.75,83.49,8.96"><forename type="first">Guillaume</forename><surname>Lengyel</surname></persName>
						</author>
						<author>
							<persName coords="1,436.83,183.75,18.53,8.96;1,135.18,194.66,44.84,8.96"><forename type="first">Guillaume</forename><surname>Bour</surname></persName>
						</author>
						<author>
							<persName coords="1,182.51,194.66,30.13,8.96"><surname>Lample</surname></persName>
						</author>
						<author>
							<persName coords="1,220.15,194.66,56.18,8.96"><forename type="first">Renard</forename><surname>Lélio</surname></persName>
						</author>
						<author>
							<persName coords="1,278.82,194.66,63.87,8.96"><forename type="first">Lucile</forename><surname>Lavaud</surname></persName>
						</author>
						<author>
							<persName coords="1,345.18,194.66,92.06,8.96"><forename type="first">Marie-Anne</forename><surname>Saulnier</surname></persName>
						</author>
						<author>
							<persName coords="1,439.73,194.66,34.63,8.96;1,126.09,205.57,26.37,8.96"><forename type="first">Pierre</forename><surname>Lachaux</surname></persName>
						</author>
						<author>
							<persName coords="1,154.95,205.57,64.77,8.96"><forename type="first">Sandeep</forename><surname>Stock</surname></persName>
						</author>
						<author>
							<persName coords="1,222.21,205.57,92.46,8.96"><forename type="first">Sophia</forename><surname>Subramanian</surname></persName>
						</author>
						<author>
							<persName coords="1,317.16,205.57,60.59,8.96"><forename type="first">Szymon</forename><surname>Yang</surname></persName>
						</author>
						<author>
							<persName coords="1,380.25,205.57,69.69,8.96"><forename type="first">Teven</forename><surname>Antoniak</surname></persName>
						</author>
						<author>
							<persName coords="1,452.43,205.57,31.49,8.96;1,121.71,216.48,42.63,8.96"><forename type="first">Théophile</forename><surname>Le Scao</surname></persName>
						</author>
						<author>
							<persName coords="1,166.83,216.48,68.43,8.96"><forename type="first">Thibaut</forename><surname>Gervet</surname></persName>
						</author>
						<author>
							<persName coords="1,237.76,216.48,65.62,8.96"><forename type="first">Thomas</forename><surname>Lavril</surname></persName>
						</author>
						<author>
							<persName coords="1,305.87,216.48,70.02,8.96"><forename type="first">Timothée</forename><surname>Wang</surname></persName>
						</author>
						<author>
							<persName coords="1,378.38,216.48,72.15,8.96"><forename type="first">William</forename><surname>Lacroix</surname></persName>
						</author>
						<author>
							<persName coords="1,453.02,216.48,37.27,8.96"><surname>El Sayed</surname></persName>
						</author>
						<title level="a" type="main" coord="1,237.63,101.17,136.74,15.48">Mixtral of Experts</title>
					</analytic>
					<monogr>
						<imprint>
							<date type="published" when="2024-01-08">8 Jan 2024</date>
						</imprint>
					</monogr>
					<idno type="MD5">8F0AD2AF9F6808955106DB664469322B</idno>
					<idno type="arXiv">arXiv:2401.04088v1[cs.LG]</idno>
				</biblStruct>
			</sourceDesc>
		</fileDesc>
		<encodingDesc>
			<appInfo>
				<application version="0.8.0" ident="GROBID" when="2024-02-11T17:57+0000">
					<desc>GROBID - A machine learning software for extracting information from scholarly documents</desc>
					<ref target="https://github.com/kermitt2/grobid"/>
				</application>
			</appInfo>
		</encodingDesc>
		<profileDesc>
			<abstract>
<div xmlns="http://www.tei-c.org/ns/1.0"><p>We introduce Mixtral 8x7B, a Sparse Mixture of Experts (SMoE) language model. Mixtral has the same architecture as Mistral 7B, with the difference that each layer is composed of 8 feedforward blocks (i.e. experts). For every token, at each layer, a router network selects two experts to process the current state and combine their outputs. Even though each token only sees two experts, the selected experts can be different at each timestep. As a result, each token has access to 47B parameters, but only uses 13B active parameters during inference. Mixtral was trained with a context size of 32k tokens and it outperforms or matches Llama 2 70B and GPT-3.5 across all evaluated benchmarks. In particular, Mixtral vastly outperforms Llama 2 70B on mathematics, code generation, and multilingual benchmarks. We also provide a model finetuned to follow instructions, Mixtral 8x7B -Instruct, that surpasses GPT-3.5 Turbo, Claude-2.1, Gemini Pro, and Llama 2 70B -chat model on human benchmarks. Both the base and instruct models are released under the Apache 2.0 license.</p></div>
			</abstract>
		</profileDesc>
	</teiHeader>
	<facsimile>
		<surface n="1" ulx="0.0" uly="0.0" lrx="612.0" lry="792.0"/>
		<surface n="2" ulx="0.0" uly="0.0" lrx="612.0" lry="792.0"/>
		<surface n="3" ulx="0.0" uly="0.0" lrx="612.0" lry="792.0"/>
		<surface n="4" ulx="0.0" uly="0.0" lrx="612.0" lry="792.0"/>
		<surface n="5" ulx="0.0" uly="0.0" lrx="612.0" lry="792.0"/>
		<surface n="6" ulx="0.0" uly="0.0" lrx="612.0" lry="792.0"/>
		<surface n="7" ulx="0.0" uly="0.0" lrx="612.0" lry="792.0"/>
		<surface n="8" ulx="0.0" uly="0.0" lrx="612.0" lry="792.0"/>
		<surface n="9" ulx="0.0" uly="0.0" lrx="612.0" lry="792.0"/>
		<surface n="10" ulx="0.0" uly="0.0" lrx="612.0" lry="792.0"/>
		<surface n="11" ulx="0.0" uly="0.0" lrx="612.0" lry="792.0"/>
		<surface n="12" ulx="0.0" uly="0.0" lrx="612.0" lry="792.0"/>
		<surface n="13" ulx="0.0" uly="0.0" lrx="612.0" lry="792.0"/>
	</facsimile>
	<text xml:lang="en">
		<body>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="1">Introduction</head><p>In this paper, we present Mixtral 8x7B, a sparse mixture of experts model <ref type="bibr" coords="1,397.41,594.10,31.46,8.64">(SMoE)</ref> with open weights, licensed under Apache 2.0. Mixtral outperforms Llama 2 70B and GPT-3.5 on most benchmarks. As it only uses a subset of its parameters for every token, Mixtral allows faster inference speed at low batch-sizes, and higher throughput at large batch-sizes.</p><p>Mixtral is a sparse mixture-of-experts network. It is a decoder-only model where the feedforward block picks from a set of 8 distinct groups of parameters. At every layer, for every token, a router network chooses two of these groups (the "experts") to process the token and combine their output additively. This technique increases the number of parameters of a model while controlling cost and latency, as the model only uses a fraction of the total set of parameters per token.</p><p>Mixtral is pretrained with multilingual data using a context size of 32k tokens. It either matches or exceeds the performance of Llama 2 70B and GPT-3.5, over several benchmarks. In particular, Figure <ref type="figure" coords="2,136.46,176.49,3.81,8.06">1</ref>: Mixture of Experts Layer. Each input vector is assigned to 2 of the 8 experts by a router. The layer's output is the weighted sum of the outputs of the two selected experts. In Mixtral, an expert is a standard feedforward block as in a vanilla transformer architecture.</p><p>Mixtral demonstrates superior capabilities in mathematics, code generation, and tasks that require multilingual understanding, significantly outperforming Llama 2 70B in these domains. Experiments show that Mixtral is able to successfully retrieve information from its context window of 32k tokens, regardless of the sequence length and the location of the information in the sequence.</p><p>We also present Mixtral 8x7B -Instruct, a chat model fine-tuned to follow instructions using supervised fine-tuning and Direct Preference Optimization <ref type="bibr" coords="2,345.46,271.30,15.33,8.64" target="#b24">[25]</ref>. Its performance notably surpasses that of GPT-3.5 Turbo, Claude-2.1, Gemini Pro, and Llama 2 70B -chat model on human evaluation benchmarks. Mixtral -Instruct also demonstrates reduced biases, and a more balanced sentiment profile in benchmarks such as BBQ, and BOLD.</p><p>We release both Mixtral 8x7B and Mixtral 8x7B -Instruct under the Apache 2.0 license<ref type="foot" coords="2,465.04,318.74,3.49,6.05" target="#foot_0">1</ref> , free for academic and commercial usage, ensuring broad accessibility and potential for diverse applications. To enable the community to run Mixtral with a fully open-source stack, we submitted changes to the vLLM project, which integrates Megablocks CUDA kernels for efficient inference. Skypilot also allows the deployment of vLLM endpoints on any instance in the cloud. Mixtral is based on a transformer architecture <ref type="bibr" coords="2,293.84,409.32,16.65,8.64" target="#b30">[31]</ref> and uses the same modifications as described in <ref type="bibr" coords="2,222.17,420.23,15.12,8.64" target="#b17">[18]</ref>, with the notable exceptions that Mixtral supports a fully dense context length of 32k tokens, and the feedforward blocks are replaced by Mixture-of-Expert layers (Section 2.1).</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2">Architectural details</head><p>The model architecture parameters are summarized in Table <ref type="table" coords="2,349.24,452.96,3.74,8.64" target="#tab_0">1</ref>.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.1">Sparse Mixture of Experts</head><p>We present a brief overview of the Mixture of Experts layer (Figure <ref type="figure" coords="2,376.24,491.79,3.55,8.64">1</ref>). For a more in-depth overview, see <ref type="bibr" coords="2,242.47,502.70,15.13,8.64" target="#b11">[12]</ref>. The output of the MoE module for a given input x is determined by the weighted sum of the outputs of the expert networks, where the weights are given by the gating network's output. i.e. given n expert networks {E 0 , E i , ..., E n-1 }, the output of the expert layer is given by:</p><formula xml:id="formula_0" coords="2,268.27,555.22,75.45,30.32">n-1 i=0 G(x) i • E i (x).</formula><p>Here, G(x) i denotes the n-dimensional output of the gating network for the i-th expert, and E i (x) is the output of the i-th expert network. If the gating vector is sparse, we can avoid computing the outputs of experts whose gates are zero. There are multiple alternative ways of implementing G(x) <ref type="bibr" coords="2,131.97,628.88,10.91,8.64" target="#b5">[6,</ref><ref type="bibr" coords="2,145.56,628.88,12.50,8.64" target="#b14">15,</ref><ref type="bibr" coords="2,160.76,628.88,11.91,8.64" target="#b34">35]</ref>, but a simple and performant one is implemented by taking the softmax over the Top-K logits of a linear layer <ref type="bibr" coords="2,225.87,639.79,15.27,8.64" target="#b27">[28]</ref>. We use</p><formula xml:id="formula_1" coords="2,236.63,653.89,138.73,9.65">G(x) := Softmax(TopK(x • W g )),</formula><p>where (TopK(ℓ)) i := ℓ i if ℓ i is among the top-K coordinates of logits ℓ ∈ R n and (TopK(ℓ)) i := -∞ otherwise. The value of K -the number of experts used per token -is a hyper-parameter that modulates the amount of compute used to process each token. If one increases n while keeping K fixed, one can increase the model's parameter count while keeping its computational cost effectively constant. This motivates a distinction between the model's total parameter count (commonly referenced as the sparse parameter count), which grows with n, and the number of parameters used for processing an individual token (called the active parameter count), which grows with K up to n.</p><p>MoE layers can be run efficiently on single GPUs with high performance specialized kernels. For example, Megablocks <ref type="bibr" coords="3,195.41,135.50,16.47,8.64" target="#b12">[13]</ref> casts the feed-forward network (FFN) operations of the MoE layer as large sparse matrix multiplications, significantly enhancing the execution speed and naturally handling cases where different experts get a variable number of tokens assigned to them. Moreover, the MoE layer can be distributed to multiple GPUs through standard Model Parallelism techniques, and through a particular kind of partitioning strategy called Expert Parallelism (EP) <ref type="bibr" coords="3,418.34,179.14,15.12,8.64" target="#b27">[28]</ref>. During the MoE layer's execution, tokens meant to be processed by a specific expert are routed to the corresponding GPU for processing, and the expert's output is returned to the original token location. Note that EP introduces challenges in load balancing, as it is essential to distribute the workload evenly across the GPUs to prevent overloading individual GPUs or hitting computational bottlenecks.</p><p>In a Transformer model, the MoE layer is applied independently per token and replaces the feed-forward (FFN) sub-block of the transformer block. For Mixtral we use the same SwiGLU architecture as the expert function E i (x) and set K = 2. This means each token is routed to two SwiGLU sub-blocks with different sets of weights. Taking this all together, the output y for an input token x is computed as:</p><formula xml:id="formula_2" coords="3,207.13,299.00,197.75,30.32">y = n-1 i=0 Softmax(Top2(x • W g )) i • SwiGLU i (x).</formula><p>This formulation is similar to the GShard architecture <ref type="bibr" coords="3,327.38,341.54,15.39,8.64" target="#b20">[21]</ref>, with the exceptions that we replace all FFN sub-blocks by MoE layers while GShard replaces every other block, and that GShard uses a more elaborate gating strategy for the second expert assigned to each token.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3">Results</head><p>We compare Mixtral to Llama, and re-run all benchmarks with our own evaluation pipeline for fair comparison. We measure performance on a wide variety of tasks categorized as follow:</p><p>• Commonsense Reasoning (0-shot): Hellaswag <ref type="bibr" coords="3,318.01,441.18,15.42,8.64" target="#b31">[32]</ref>, Winogrande <ref type="bibr" coords="3,393.08,441.18,15.41,8.64" target="#b25">[26]</ref>, PIQA <ref type="bibr" coords="3,442.02,441.18,10.72,8.64" target="#b2">[3]</ref>, SIQA <ref type="bibr" coords="3,485.98,441.18,15.41,8.64" target="#b26">[27]</ref>,</p><p>OpenbookQA <ref type="bibr" coords="3,176.34,452.09,15.27,8.64" target="#b21">[22]</ref>, ARC-Easy, ARC-Challenge <ref type="bibr" coords="3,312.11,452.09,10.58,8.64" target="#b7">[8]</ref>, CommonsenseQA <ref type="bibr" coords="3,404.26,452.09,16.60,8.64" target="#b29">[30]</ref> • World Knowledge (5-shot): NaturalQuestions <ref type="bibr" coords="3,308.15,466.76,15.27,8.64" target="#b19">[20]</ref>, TriviaQA <ref type="bibr" coords="3,370.35,466.76,16.60,8.64" target="#b18">[19]</ref> • Reading Comprehension (0-shot): BoolQ <ref type="bibr" coords="3,293.83,481.42,10.58,8.64" target="#b6">[7]</ref>, QuAC <ref type="bibr" coords="3,338.53,481.42,11.62,8.64" target="#b4">[5]</ref> • Math: GSM8K [9] (8-shot) with maj@8 and MATH <ref type="bibr" coords="3,331.39,496.09,16.60,8.64" target="#b16">[17]</ref> (4-shot) with maj@4 • Code: Humaneval [4] (0-shot) and MBPP <ref type="bibr" coords="3,288.51,510.76,11.62,8.64" target="#b0">[1]</ref> (3-shot) • Popular aggregated results: MMLU <ref type="bibr" coords="3,281.44,525.42,16.73,8.64" target="#b15">[16]</ref> (5-shot), BBH <ref type="bibr" coords="3,365.62,525.42,16.73,8.64" target="#b28">[29]</ref> (3-shot), and AGI Eval <ref type="bibr" coords="3,487.27,525.42,16.73,8.64" target="#b33">[34]</ref> (3-5-shot, English multiple-choice questions only)</p><p>Figure <ref type="figure" coords="3,134.96,690.90,3.66,8.06">2</ref>: Performance of Mixtral and different Llama models on a wide range of benchmarks. All models were re-evaluated on all metrics with our evaluation pipeline for accurate comparison. Mixtral outperforms or matches Llama 2 70B on all benchmarks. In particular, it is vastly superior in mathematics and code generation.   Detailed results for Mixtral, Mistral 7B and Llama 2 7B/13B/70B and Llama 1 34B<ref type="foot" coords="4,448.56,463.96,3.49,6.05" target="#foot_1">2</ref> are reported in Table <ref type="table" coords="4,145.40,476.54,3.81,8.64" target="#tab_2">2</ref>. Figure <ref type="figure" coords="4,189.48,476.54,5.08,8.64">2</ref> compares the performance of Mixtral with the Llama models in different categories. Mixtral surpasses Llama 2 70B across most metrics. In particular, Mixtral displays a superior performance in code and mathematics benchmarks.</p><p>Size and Efficiency. We compare our performance to the Llama 2 family, aiming to understand Mixtral models' efficiency in the cost-performance spectrum (see Figure <ref type="figure" coords="4,406.01,525.66,3.67,8.64" target="#fig_0">3</ref>). As a sparse Mixtureof-Experts model, Mixtral only uses 13B active parameters for each token. With 5x lower active parameters, Mixtral is able to outperform Llama 2 70B across most categories.</p><p>Note that this analysis focuses on the active parameter count (see Section 2.1), which is directly proportional to the inference compute cost, but does not consider the memory costs and hardware utilization. The memory costs for serving Mixtral are proportional to its sparse parameter count, 47B, which is still smaller than Llama 2 70B. As for device utilization, we note that the SMoEs layer introduces additional overhead due to the routing mechanism and due to the increased memory loads when running more than one expert per device. They are more suitable for batched workloads where one can reach a good degree of arithmetic intensity.</p><p>Comparison with Llama 2 70B and GPT-3.5. In Table <ref type="table" coords="4,327.81,645.71,3.66,8.64" target="#tab_3">3</ref>, we report the performance of Mixtral 8x7B compared to Llama 2 70B and GPT-3.5. We observe that Mixtral performs similarly or above the two other models. On MMLU, Mixtral obtains a better performance, despite its significantly smaller capacity (47B tokens compared to 70B). For MT Bench, we report the performance of the latest GPT-3.5-Turbo model available, gpt-3.5-turbo-1106. Evaluation Differences. On some benchmarks, there are some differences between our evaluation protocol and the one reported in the Llama 2 paper: 1) on MBPP, we use the hand-verified subset 2) on TriviaQA, we do not provide Wikipedia contexts.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.1">Multilingual benchmarks</head><p>Compared to Mistral 7B, we significantly upsample the proportion of multilingual data during pretraining. The extra capacity allows Mixtral to perform well on multilingual benchmarks while maintaining a high accuracy in English. In particular, Mixtral significantly outperforms Llama 2 70B in French, German, Spanish, and Italian, as shown in Table <ref type="table" coords="5,345.47,348.85,3.74,8.64" target="#tab_5">4</ref>.  </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.2">Long range performance</head><p>To assess the capabilities of Mixtral to tackle long context, we evaluate it on the passkey retrieval task introduced in <ref type="bibr" coords="5,183.81,485.33,15.42,8.64" target="#b22">[23]</ref>, a synthetic task designed to measure the ability of the model to retrieve a passkey inserted randomly in a long prompt. Results in Figure <ref type="figure" coords="5,357.60,496.24,4.96,8.64" target="#fig_1">4</ref> (Left) show that Mixtral achieves a 100% retrieval accuracy regardless of the context length or the position of passkey in the sequence. Figure <ref type="figure" coords="5,135.62,518.05,4.88,8.64" target="#fig_1">4</ref> (Right) shows that the perplexity of Mixtral on a subset of the proof-pile dataset <ref type="bibr" coords="5,452.99,518.05,11.48,8.64" target="#b1">[2]</ref> decreases monotonically as the size of the context increases.  To identify possible flaws to be by fine-tuning / preference modeling, we measure the base model performance on Bias Benchmark for QA (BBQ) <ref type="bibr" coords="6,245.17,131.00,16.74,8.64" target="#b23">[24]</ref> and Bias in Open-Ended Language Generation Dataset (BOLD) <ref type="bibr" coords="6,180.90,152.82,15.42,8.64" target="#b9">[10]</ref>. BBQ is a dataset of hand-written question sets that target attested social biases against nine different socially-relevant categories: age, disability status, gender identity, nationality, physical appearance, race/ethnicity, religion, socio-economic status, sexual orientation. BOLD is a large-scale dataset that consists of 23,679 English text generation prompts for bias benchmarking across five domains.</p><p>We benchmark Llama 2 and Mixtral on BBQ and BOLD with our evaluation framework and report the results in Table <ref type="table" coords="6,189.60,278.30,3.81,8.64">5</ref>. Compared to Llama 2, Mixtral presents less bias on the BBQ benchmark (56.0% vs 51.5%). For each group in BOLD, a higher average sentiment score means more positive sentiments and a lower standard deviation indicates less bias within the group. Overall, Mixtral displays more positive sentiments than Llama 2, with similar variances within each group.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4">Instruction Fine-tuning</head><p>We train Mixtral -Instruct using supervised fine-tuning (SFT) on an instruction dataset followed by Direct Preference Optimization (DPO) <ref type="bibr" coords="6,261.50,384.73,16.47,8.64" target="#b24">[25]</ref> on a paired feedback dataset. Mixtral -Instruct reaches a score of 8.30 on MT-Bench <ref type="bibr" coords="6,216.88,395.64,16.46,8.64" target="#b32">[33]</ref> (see Table <ref type="table" coords="6,277.32,395.64,3.52,8.64" target="#tab_2">2</ref>), making it the best open-weights model as of December 2023. Independent human evaluation conducted by LMSys is reported in Figure <ref type="figure" coords="6,432.91,406.55,5.04,8.64" target="#fig_2">6</ref> <ref type="foot" coords="6,437.95,404.88,3.49,6.05" target="#foot_3">3</ref> and shows that Mixtral -Instruct outperforms GPT-3.5-Turbo, Gemini Pro, Claude-2.1, and Llama 2 70B chat. </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5">Routing analysis</head><p>In this section, we perform a small analysis on the expert selection by the router. In particular, we are interested to see if during training some experts specialized to some specific domains (e.g. mathematics, biology, philosophy, etc.).</p><p>To investigate this, we measure the distribution of selected experts on different subsets of The Pile validation dataset <ref type="bibr" coords="7,181.50,148.44,15.42,8.64" target="#b13">[14]</ref>. Results are presented in Figure <ref type="figure" coords="7,332.60,148.44,3.81,8.64">7</ref>, for layers 0, 15, and 31 (layers 0 and 31 respectively being the first and the last layers of the model). Surprisingly, we do not observe obvious patterns in the assignment of experts based on the topic. For instance, at all layers, the distribution of expert assignment is very similar for ArXiv papers (written in Latex), for biology (PubMed Abstracts), and for Philosophy (PhilPapers) documents.</p><p>Only for DM Mathematics we note a marginally different distribution of experts. This divergence is likely a consequence of the dataset's synthetic nature and its limited coverage of the natural language spectrum, and is particularly noticeable at the first and last layers, where the hidden states are very correlated to the input and output embeddings respectively.</p><p>This suggests that the router does exhibit some structured syntactic behavior. Figure <ref type="figure" coords="7,469.95,257.58,5.08,8.64" target="#fig_3">8</ref> shows examples of text from different domains (Python code, mathematics, and English), where each token is highlighted with a background color corresponding to its selected expert. The figure shows that words such as 'self' in Python and 'Question' in English often get routed through the same expert even though they involve multiple tokens. Similarly, in code, the indentation tokens are always assigned to the same experts, particularly at the first and last layers where the hidden states are more correlated to the input and output of the model.</p><p>We also note from Figure <ref type="figure" coords="7,211.99,339.43,5.00,8.64" target="#fig_3">8</ref> that consecutive tokens are often assigned the same experts. In fact, we observe some degree of positional locality in The Pile datasets. Table <ref type="table" coords="8,130.84,193.88,3.70,8.06">5</ref>: Percentage of expert assignment repetitions. We evaluate the proportion of times the same expert is assigned to a token i and its following token i+1. We report whether the first chosen expert is the same, or whether the same expert is observed as first or second choice in consecutive tokens. For reference, the expected proportion of repetitions in the case of random assignments is 1 8 = 12.5% for "First choice" and 1 -6 8 5</p><p>7 ≈ 46% for "First and second choice". Repetitions at the first layer are close to random, but are significantly higher at layers 15 and 31. The high number of repetitions shows that expert choice exhibits high temporal locality at these layers. consecutive assignments is significantly higher than random for higher layers. This has implications in how one might optimize the model for fast training and inference. For example, cases with high locality are more likely to cause over-subscription of certain experts when doing Expert Parallelism. Conversely, this locality can be leveraged for caching, as is done in <ref type="bibr" coords="8,379.45,307.47,15.33,8.64" target="#b10">[11]</ref>. A more complete view of these same expert frequency is provided for all layers and across datasets in Figure <ref type="figure" coords="8,429.12,318.38,9.76,8.64" target="#fig_5">10</ref> in the Appendix.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="6">Conclusion</head><p>In this paper, we introduced Mixtral 8x7B, the first mixture-of-experts network to reach a state-of-theart performance among open-source models. Mixtral 8x7B Instruct outperforms Claude-2.1, Gemini Pro, and GPT-3.5 Turbo on human evaluation benchmarks. Because it only uses two experts at each time step, Mixtral only uses 13B active parameters per token while outperforming the previous best model using 70B parameters per token (Llama 2 70B). We are making our trained and fine-tuned models publicly available under the Apache 2.0 license. By sharing our models, we aim to facilitate the development of new techniques and applications that can benefit a wide range of industries and domains.   </p></div><figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_0" coords="4,108.00,410.56,397.12,8.06;4,108.00,420.53,396.00,8.12;4,108.00,430.84,396.00,7.77;4,108.00,440.80,203.99,7.77;4,136.45,214.81,336.60,192.97"><head>Figure 3 :</head><label>3</label><figDesc>Figure 3: Results on MMLU, commonsense reasoning, world knowledge and reading comprehension, math and code for Mistral (7B/8x7B) vs Llama 2 (7B/13B/70B). Mixtral largely outperforms Llama 2 70B on all benchmarks, except on reading comprehension benchmarks while using 5x lower active parameters. It is also vastly superior to Llama 2 70B on code and math.</figDesc><graphic coords="4,136.45,214.81,336.60,192.97" type="bitmap" /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_1" coords="5,108.00,684.04,396.22,8.12;5,108.00,694.35,396.00,7.77;5,108.00,704.31,280.25,7.77;5,272.34,544.97,217.81,139.28"><head>Figure 4 :</head><label>4</label><figDesc>Figure 4: Long range performance of Mixtral. (Left) Mixtral has 100% retrieval accuracy of the Passkey task regardless of the location of the passkey and length of the input sequence. (Right) The perplexity of Mixtral on the proof-pile dataset decreases monotonically as the context length increases.</figDesc><graphic coords="5,272.34,544.97,217.81,139.28" type="bitmap" /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_2" coords="6,108.00,648.78,396.00,8.12;6,108.00,659.10,396.00,7.77;6,107.70,669.06,381.47,7.77;6,127.80,444.33,356.39,196.70"><head>Figure 6 :</head><label>6</label><figDesc>Figure 6: LMSys Leaderboard. (Screenshot from Dec 22, 2023) Mixtral 8x7B Instruct v0.1 achieves an Arena Elo rating of 1121 outperforming Claude-2.1 (1117), all versions of GPT-3.5-Turbo (1117 best), Gemini Pro (1111), and Llama-2-70b-chat (1077). Mixtral is currently the best open-weights model by a large margin.</figDesc><graphic coords="6,127.80,444.33,356.39,196.70" type="bitmap" /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_3" coords="8,108.00,700.86,396.00,8.12;8,108.00,711.17,381.51,7.77;8,108.00,463.00,395.99,230.10"><head>Figure 8 :</head><label>8</label><figDesc>Figure 8: Text samples where each token is colored with the first expert choice. The selection of experts appears to be more aligned with the syntax rather than the domain, especially at the initial and final layers.</figDesc><graphic coords="8,108.00,463.00,395.99,230.10" type="bitmap" /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_4" coords="12,108.00,682.32,396.00,8.06;12,108.00,692.28,396.00,8.12;12,108.00,702.59,172.48,7.77;12,283.91,700.67,3.65,5.24;12,283.91,707.39,3.65,5.24;12,288.76,702.59,189.93,7.77"><head>Figure 9 :</head><label>9</label><figDesc>Figure9: Proportion of tokens assigned to each expert on different subsets from The Pile dataset, separated by whether the expert was selected as first or second choice, or either. The "Either choice" case is equivalent to Figure7. The gray dashed vertical line marks1  8 , i.e. the proportion expected with uniform sampling.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_5" coords="13,108.00,532.35,396.00,8.12;13,108.00,542.67,396.00,7.77;13,108.00,552.63,182.55,7.77"><head>Figure 10 :</head><label>10</label><figDesc>Figure 10: Repeated consecutive assignments per MoE layer. Repeated assignments occur a lot more often than they would with uniform assignments (materialized by the dashed lines). Patterns are similar across datasets with less repetitions for DM Mathematics.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" coords="3,108.01,554.02,395.98,138.13"><head></head><label></label><figDesc></figDesc><graphic coords="3,108.01,554.02,395.98,138.13" type="bitmap" /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_0" coords="2,394.81,416.02,108.96,128.43"><head>Table 1 :</head><label>1</label><figDesc>Model architecture.</figDesc><table coords="2,401.46,416.02,96.18,113.01"><row><cell>Parameter</cell><cell>Value</cell></row><row><cell>dim</cell><cell>4096</cell></row><row><cell>n_layers</cell><cell>32</cell></row><row><cell>head_dim</cell><cell>128</cell></row><row><cell>hidden_dim</cell><cell>14336</cell></row><row><cell>n_heads</cell><cell>32</cell></row><row><cell>n_kv_heads</cell><cell>8</cell></row><row><cell>context_len</cell><cell>32768</cell></row><row><cell>vocab_size</cell><cell>32000</cell></row><row><cell>num_experts</cell><cell>8</cell></row><row><cell>top_k_experts</cell><cell>2</cell></row></table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_2" coords="4,107.70,174.18,396.29,18.09"><head>Table 2 :</head><label>2</label><figDesc>Comparison of Mixtral with Llama. Mixtral outperforms or matches Llama 2 70B performance on almost all popular benchmarks while using 5x fewer active parameters during inference.</figDesc><table /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_3" coords="5,107.70,56.57,396.30,184.78"><head>Table 3 :</head><label>3</label><figDesc>Comparison of Mixtral with Llama 2 70B and GPT-3.5. Mixtral outperforms or matches Llama 2 70B and GPT-3.5 performance on most metrics.</figDesc><table coords="5,178.89,56.57,253.15,157.86"><row><cell></cell><cell>LLaMA 2 70B</cell><cell>GPT-3.5</cell><cell>Mixtral 8x7B</cell></row><row><cell>MMLU (MCQ in 57 subjects)</cell><cell>69.9%</cell><cell>70.0%</cell><cell>70.6%</cell></row><row><cell>HellaSwag (10-shot)</cell><cell>87.1%</cell><cell>85.5%</cell><cell>86.7%</cell></row><row><cell>ARC Challenge (25-shot)</cell><cell>85.1%</cell><cell>85.2%</cell><cell>85.8%</cell></row><row><cell>WinoGrande (5-shot)</cell><cell>83.2%</cell><cell>81.6%</cell><cell>81.2%</cell></row><row><cell>MBPP (pass@1)</cell><cell>49.8%</cell><cell>52.2%</cell><cell>60.7%</cell></row><row><cell>GSM-8K (5-shot)</cell><cell>53.6%</cell><cell>57.1%</cell><cell>58.4%</cell></row><row><cell>MT Bench (for Instruct Models)</cell><cell>6.86</cell><cell>8.32</cell><cell>8.30</cell></row></table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_5" coords="5,107.70,424.97,397.42,18.08"><head>Table 4 :</head><label>4</label><figDesc></figDesc><table /><note coords="5,141.04,424.97,364.08,8.12;5,108.00,435.28,366.87,7.77"><p>Comparison of Mixtral with Llama on Multilingual Benchmarks. On ARC Challenge, Hellaswag, and MMLU, Mixtral outperforms Llama 2 70B on 4 languages: French, German, Spanish, and Italian.</p></note></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_7" coords="7,105.49,350.33,400.16,368.61"><head></head><label></label><figDesc>Table5shows the proportion of consecutive tokens that get the same expert assignments per domain and layer. The proportion of repeated Figure 7: Proportion of tokens assigned to each expert on different domains from The Pile dataset for layers 0, 15, and 31. The gray dashed vertical line marks 1/8, i.e. the proportion expected with uniform sampling.Here, we consider experts that are either selected as a first or second choice by the router. A breakdown of the proportion of assignments done in each case cane be seen in Figure9in the Appendix.</figDesc><table coords="7,105.49,399.32,370.66,264.11"><row><cell></cell><cell></cell><cell></cell><cell cols="2">First choice</cell><cell></cell><cell></cell><cell cols="3">First or second choice</cell></row><row><cell></cell><cell></cell><cell></cell><cell>Layer 0</cell><cell>Layer 15</cell><cell cols="2">Layer 31</cell><cell>Layer 0</cell><cell>Layer 15</cell><cell>Layer 31</cell></row><row><cell cols="2">ArXiv</cell><cell></cell><cell>14.0%</cell><cell>27.9%</cell><cell></cell><cell>22.7%</cell><cell>46.5%</cell><cell>62.3%</cell><cell>52.9%</cell></row><row><cell cols="3">DM Mathematics</cell><cell>14.1%</cell><cell>28.4%</cell><cell></cell><cell>19.7%</cell><cell>44.9%</cell><cell>67.0%</cell><cell>44.5%</cell></row><row><cell cols="2">Github</cell><cell></cell><cell>14.9%</cell><cell>28.1%</cell><cell></cell><cell>19.7%</cell><cell>49.9%</cell><cell>66.9%</cell><cell>49.2%</cell></row><row><cell cols="2">Gutenberg</cell><cell></cell><cell>13.9%</cell><cell>26.1%</cell><cell></cell><cell>26.3%</cell><cell>49.5%</cell><cell>63.1%</cell><cell>52.2%</cell></row><row><cell cols="2">PhilPapers</cell><cell></cell><cell>13.6%</cell><cell>25.3%</cell><cell></cell><cell>22.1%</cell><cell>46.9%</cell><cell>61.9%</cell><cell>51.3%</cell></row><row><cell cols="3">PubMed Abstracts</cell><cell>14.2%</cell><cell>24.6%</cell><cell></cell><cell>22.0%</cell><cell>48.6%</cell><cell>61.6%</cell><cell>51.8%</cell></row><row><cell cols="3">StackExchange</cell><cell>13.6%</cell><cell>27.2%</cell><cell></cell><cell>23.6%</cell><cell>48.2%</cell><cell>64.6%</cell><cell>53.6%</cell></row><row><cell cols="3">Wikipedia (en)</cell><cell>14.4%</cell><cell>23.6%</cell><cell></cell><cell>25.3%</cell><cell>49.8%</cell><cell>62.1%</cell><cell>51.8%</cell></row><row><cell>Selection proportion</cell><cell>0.20 0.15 0.10 0.05 0 0 0.05 0.10 0.15 0.20 0 0.05 0.10 0.15 0.20</cell><cell>0</cell><cell>1</cell><cell>2</cell><cell cols="2">layer: 0 layer: 15 Expert ID 3 4 layer: 31</cell><cell>5</cell><cell>6</cell><cell>7</cell></row><row><cell></cell><cell></cell><cell></cell><cell>ArXiv</cell><cell>Github</cell><cell></cell><cell cols="2">PhilPapers</cell><cell cols="2">StackExchange</cell></row><row><cell></cell><cell></cell><cell></cell><cell>DM Mathematics</cell><cell cols="2">Gutenberg</cell><cell cols="2">PubMed Abstracts</cell><cell cols="2">Wikipedia (en)</cell></row></table></figure>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="1" xml:id="foot_0" coords="2,124.14,714.52,203.36,7.47"><p>https://mistral.ai/news/mixtral-of-experts/</p></note>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="2" xml:id="foot_1" coords="4,124.14,714.16,51.80,7.77"><p>Since Llama 2</p></note>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" xml:id="foot_2" coords="4,178.18,714.16,223.53,7.77"><p>34B was not open-sourced, we report results for Llama 1 34B.</p></note>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="3" xml:id="foot_3" coords="6,124.14,714.52,288.07,7.47"><p>https://huggingface.co/spaces/lmsys/chatbot-arena-leaderboard</p></note>
		</body>
		<back>

			<div type="acknowledgement">
<div><head>Acknowledgements</head><p>We thank the <rs type="institution">CoreWeave and Scaleway</rs> teams for technical support as we trained our models. We are grateful to <rs type="institution">NVIDIA</rs> for supporting us in integrating TensorRT-LLM and Triton and working alongside us to make a sparse mixture of experts compatible with TensorRT-LLM.</p></div>
			</div>			<div type="references">

				<listBibl>

<biblStruct coords="9,129.58,170.06,374.42,8.64;9,129.58,180.97,374.42,8.64;9,129.58,191.70,232.89,8.82" xml:id="b0">
	<monogr>
		<title level="m" type="main" coord="9,385.84,180.97,118.16,8.64;9,129.58,191.88,65.26,8.64">Program synthesis with large language models</title>
		<author>
			<persName coords=""><forename type="first">Jacob</forename><surname>Austin</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Augustus</forename><surname>Odena</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Maxwell</forename><surname>Nye</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Maarten</forename><surname>Bosma</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Henryk</forename><surname>Michalewski</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">David</forename><surname>Dohan</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Ellen</forename><surname>Jiang</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Carrie</forename><surname>Cai</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Michael</forename><surname>Terry</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Quoc</forename><surname>Le</surname></persName>
		</author>
		<idno type="arXiv">arXiv:2108.07732</idno>
		<imprint>
			<date type="published" when="2021">2021</date>
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct coords="9,129.58,207.32,375.67,8.64;9,129.22,218.23,374.78,8.64;9,129.58,228.96,257.52,8.82" xml:id="b1">
	<monogr>
		<title level="m" type="main" coord="9,388.91,218.23,115.09,8.64;9,129.58,229.14,89.95,8.64">Llemma: An open language model for mathematics</title>
		<author>
			<persName coords=""><forename type="first">Zhangir</forename><surname>Azerbayev</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Hailey</forename><surname>Schoelkopf</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Keiran</forename><surname>Paster</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Marco</forename><forename type="middle">Dos</forename><surname>Santos</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Stephen</forename><surname>Mcaleer</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Albert</forename><forename type="middle">Q</forename><surname>Jiang</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Jia</forename><surname>Deng</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Stella</forename><surname>Biderman</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Sean</forename><surname>Welleck</surname></persName>
		</author>
		<idno type="arXiv">arXiv:2310.10631</idno>
		<imprint>
			<date type="published" when="2023">2023</date>
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct coords="9,129.58,244.58,376.07,8.64;9,129.58,255.31,374.42,8.82;9,129.58,266.22,148.77,8.82" xml:id="b2">
	<analytic>
		<title level="a" type="main" coord="9,387.66,244.58,117.99,8.64;9,129.58,255.49,154.69,8.64">PIQA: Reasoning about Physical Commonsense in Natural Language</title>
		<author>
			<persName coords=""><forename type="first">Yonatan</forename><surname>Bisk</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Rowan</forename><surname>Zellers</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Ronan</forename><surname>Le Bras</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Jianfeng</forename><surname>Gao</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Yejin</forename><surname>Choi</surname></persName>
		</author>
		<idno type="DOI">10.1609/aaai.v34i05.6239</idno>
	</analytic>
	<monogr>
		<title level="j">Proceedings of the AAAI Conference on Artificial Intelligence</title>
		<title level="j" type="abbrev">AAAI</title>
		<idno type="ISSN">2159-5399</idno>
		<idno type="ISSNe">2374-3468</idno>
		<imprint>
			<biblScope unit="volume">34</biblScope>
			<biblScope unit="issue">05</biblScope>
			<biblScope unit="page" from="7432" to="7439" />
			<date type="published" when="2020-04-03">2020</date>
			<publisher>Association for the Advancement of Artificial Intelligence (AAAI)</publisher>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="9,129.58,281.84,374.41,8.64;9,129.58,292.75,374.42,8.64;9,129.58,303.48,296.80,8.82" xml:id="b3">
	<monogr>
		<title level="m" type="main" coord="9,438.55,292.75,65.45,8.64;9,129.58,303.66,129.38,8.64">Evaluating large language models trained on code</title>
		<author>
			<persName coords=""><forename type="first">Mark</forename><surname>Chen</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Jerry</forename><surname>Tworek</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Heewoo</forename><surname>Jun</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Qiming</forename><surname>Yuan</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Henrique</forename><surname>Ponde De Oliveira Pinto</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Jared</forename><surname>Kaplan</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Harri</forename><surname>Edwards</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Yuri</forename><surname>Burda</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Nicholas</forename><surname>Joseph</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Greg</forename><surname>Brockman</surname></persName>
		</author>
		<idno type="arXiv">arXiv:2107.03374</idno>
		<imprint>
			<date type="published" when="2021">2021</date>
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct coords="9,129.58,319.10,374.42,8.64;9,129.58,329.83,375.67,8.82;9,129.58,340.92,22.42,8.64" xml:id="b4">
	<analytic>
		<title level="a" type="main">QuAC: Question Answering in Context</title>
		<author>
			<persName coords=""><forename type="first">Eunsol</forename><surname>Choi</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">He</forename><surname>He</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Mohit</forename><surname>Iyyer</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Mark</forename><surname>Yatskar</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Wen-Tau</forename><surname>Yih</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Yejin</forename><surname>Choi</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Percy</forename><surname>Liang</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Luke</forename><surname>Zettlemoyer</surname></persName>
		</author>
		<idno type="DOI">10.18653/v1/d18-1241</idno>
		<idno type="arXiv">arXiv:1808.07036</idno>
	</analytic>
	<monogr>
		<title level="m" coord="9,208.84,330.01,150.46,8.64">Proceedings of the 2018 Conference on Empirical Methods in Natural Language Processing</title>
		<meeting>the 2018 Conference on Empirical Methods in Natural Language Processing</meeting>
		<imprint>
			<publisher>Association for Computational Linguistics</publisher>
			<date type="published" when="2018">2018</date>
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct coords="9,129.58,356.36,374.42,8.64;9,129.58,367.27,374.42,8.64;9,129.58,378.00,375.67,8.82;9,129.58,389.08,129.51,8.64" xml:id="b5">
	<analytic>
		<title level="a" type="main" coord="9,473.66,367.27,30.34,8.64;9,129.58,378.18,161.37,8.64">Unified scaling laws for routed language models</title>
		<author>
			<persName coords=""><forename type="first">Aidan</forename><surname>Clark</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Diego</forename><surname>De</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Las</forename><surname>Casas</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Aurelia</forename><surname>Guy</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Arthur</forename><surname>Mensch</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Michela</forename><surname>Paganini</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Jordan</forename><surname>Hoffmann</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Bogdan</forename><surname>Damoc</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Blake</forename><surname>Hechtman</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Trevor</forename><surname>Cai</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Sebastian</forename><surname>Borgeaud</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m" coord="9,310.01,378.00,190.81,8.59">International Conference on Machine Learning</title>
		<imprint>
			<publisher>PMLR</publisher>
			<date type="published" when="2022">2022</date>
			<biblScope unit="page" from="4057" to="4086" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="9,129.58,404.53,374.42,8.64;9,129.58,415.44,376.16,8.64;9,129.58,426.17,159.58,8.82" xml:id="b6">
	<analytic>
		<title level="a" type="main"></title>
		<author>
			<persName coords=""><forename type="first">Christopher</forename><surname>Clark</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Kenton</forename><surname>Lee</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Ming-Wei</forename><surname>Chang</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Tom</forename><surname>Kwiatkowski</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Michael</forename><surname>Collins</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Kristina</forename><surname>Toutanova</surname></persName>
		</author>
		<idno type="DOI">10.18653/v1/n19-1300</idno>
		<idno type="arXiv">arXiv:1905.10044</idno>
	</analytic>
	<monogr>
		<title level="m" coord="9,216.22,415.44,285.43,8.64">Proceedings of the 2019 Conference of the North</title>
		<meeting>the 2019 Conference of the North</meeting>
		<imprint>
			<publisher>Association for Computational Linguistics</publisher>
			<date type="published" when="2019">2019</date>
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct coords="9,129.58,441.79,375.66,8.64;9,129.58,452.70,374.42,8.64;9,129.58,463.43,203.83,8.82" xml:id="b7">
	<monogr>
		<title level="m" type="main" coord="9,217.59,452.70,286.41,8.64;9,129.58,463.60,36.60,8.64">Think you have solved question answering? try arc, the ai2 reasoning challenge</title>
		<author>
			<persName coords=""><forename type="first">Peter</forename><surname>Clark</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Isaac</forename><surname>Cowhey</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Oren</forename><surname>Etzioni</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Tushar</forename><surname>Khot</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Ashish</forename><surname>Sabharwal</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Carissa</forename><surname>Schoenick</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Oyvind</forename><surname>Tafjord</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1803.05457</idno>
		<imprint>
			<date type="published" when="2018">2018</date>
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct coords="9,129.58,479.05,375.66,8.64;9,129.58,489.96,374.42,8.64;9,129.58,500.69,271.39,8.82" xml:id="b8">
	<monogr>
		<title level="m" type="main" coord="9,423.13,489.96,80.87,8.64;9,129.58,500.86,103.83,8.64">Training verifiers to solve math word problems</title>
		<author>
			<persName coords=""><forename type="first">Karl</forename><surname>Cobbe</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Vineet</forename><surname>Kosaraju</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Mohammad</forename><surname>Bavarian</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Mark</forename><surname>Chen</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Heewoo</forename><surname>Jun</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Lukasz</forename><surname>Kaiser</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Matthias</forename><surname>Plappert</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Jerry</forename><surname>Tworek</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Jacob</forename><surname>Hilton</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Reiichiro</forename><surname>Nakano</surname></persName>
		</author>
		<idno type="arXiv">arXiv:2110.14168</idno>
		<imprint>
			<date type="published" when="2021">2021</date>
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct coords="9,129.58,516.31,374.42,8.64;9,129.58,527.21,374.42,8.64;9,129.58,537.95,376.16,8.82;9,129.58,548.85,161.91,8.82" xml:id="b9">
	<analytic>
		<title level="a" type="main" coord="9,242.49,527.21,261.52,8.64;9,129.58,538.12,79.55,8.64">BOLD</title>
		<author>
			<persName coords=""><forename type="first">Jwala</forename><surname>Dhamala</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Tony</forename><surname>Sun</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Varun</forename><surname>Kumar</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Satyapriya</forename><surname>Krishna</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Yada</forename><surname>Pruksachatkun</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Kai-Wei</forename><surname>Chang</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Rahul</forename><surname>Gupta</surname></persName>
		</author>
		<idno type="DOI">10.1145/3442188.3445924</idno>
	</analytic>
	<monogr>
		<title level="m" coord="9,227.62,537.95,278.12,8.59;9,129.58,548.85,67.78,8.59">Proceedings of the 2021 ACM Conference on Fairness, Accountability, and Transparency</title>
		<meeting>the 2021 ACM Conference on Fairness, Accountability, and Transparency</meeting>
		<imprint>
			<publisher>ACM</publisher>
			<date type="published" when="2021-03">2021</date>
			<biblScope unit="page" from="862" to="872" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="9,129.58,564.47,374.42,8.64;9,129.58,575.20,206.36,8.82" xml:id="b10">
	<analytic>
		<title level="a" type="main" coord="9,269.32,564.47,234.68,8.64;9,129.58,575.38,39.27,8.64">Preprint repository arXiv achieves milestone million uploads</title>
		<author>
			<persName coords=""><forename type="first">Artyom</forename><surname>Eliseev</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Denis</forename><surname>Mazur</surname></persName>
		</author>
		<idno type="DOI">10.1063/pt.5.028530</idno>
		<idno type="arXiv">arXiv:2312.17238</idno>
	</analytic>
	<monogr>
		<title level="j">Physics Today</title>
		<title level="j" type="abbrev">Phys. Today</title>
		<idno type="ISSNe">1945-0699</idno>
		<imprint>
			<date type="published" when="2023">2023</date>
			<publisher>AIP Publishing</publisher>
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct coords="9,129.58,590.83,376.16,8.64;9,129.58,601.56,159.58,8.82" xml:id="b11">
	<analytic>
		<title level="a" type="main" coord="9,305.77,590.83,196.11,8.64">Preprint repository arXiv achieves milestone million uploads</title>
		<author>
			<persName coords=""><forename type="first">William</forename><surname>Fedus</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Jeff</forename><surname>Dean</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Barret</forename><surname>Zoph</surname></persName>
		</author>
		<idno type="DOI">10.1063/pt.5.028530</idno>
		<idno type="arXiv">arXiv:2209.01667</idno>
	</analytic>
	<monogr>
		<title level="j">Physics Today</title>
		<title level="j" type="abbrev">Phys. Today</title>
		<idno type="ISSNe">1945-0699</idno>
		<imprint>
			<date type="published" when="2022">2022</date>
			<publisher>AIP Publishing</publisher>
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct coords="9,129.58,617.18,374.43,8.64;9,129.58,627.91,293.89,8.82" xml:id="b12">
	<monogr>
		<author>
			<persName coords=""><forename type="first">Trevor</forename><surname>Gale</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Deepak</forename><surname>Narayanan</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Cliff</forename><surname>Young</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Matei</forename><surname>Zaharia</surname></persName>
		</author>
		<idno type="arXiv">arXiv:2211.15841</idno>
		<title level="m" coord="9,390.15,617.18,113.86,8.64;9,129.58,628.09,126.67,8.64">Megablocks: Efficient sparse training with mixture-of-experts</title>
		<imprint>
			<date type="published" when="2022">2022</date>
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct coords="9,129.58,643.53,374.42,8.64;9,129.58,654.44,374.42,8.64;9,129.58,665.17,273.14,8.82" xml:id="b13">
	<monogr>
		<title level="m" type="main" coord="9,352.88,654.44,151.12,8.64;9,129.58,665.35,105.52,8.64">The pile: An 800gb dataset of diverse text for language modeling</title>
		<author>
			<persName coords=""><forename type="first">Leo</forename><surname>Gao</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Stella</forename><surname>Biderman</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Sid</forename><surname>Black</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Laurence</forename><surname>Golding</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Travis</forename><surname>Hoppe</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Charles</forename><surname>Foster</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Jason</forename><surname>Phang</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Horace</forename><surname>He</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Anish</forename><surname>Thite</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Noa</forename><surname>Nabeshima</surname></persName>
		</author>
		<idno type="arXiv">arXiv:2101.00027</idno>
		<imprint>
			<date type="published" when="2020">2020</date>
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct coords="9,129.58,680.79,375.67,8.64;9,129.58,691.70,374.42,8.64;9,129.58,702.43,374.42,8.82;9,129.33,713.34,131.45,8.82" xml:id="b14">
	<analytic>
		<title level="a" type="main" coord="9,310.03,691.70,193.98,8.64;9,129.58,702.61,194.51,8.64">Dselect-k: Differentiable selection in the mixture of experts with applications to multi-task learning</title>
		<author>
			<persName coords=""><forename type="first">Hussein</forename><surname>Hazimeh</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Zhe</forename><surname>Zhao</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Aakanksha</forename><surname>Chowdhery</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Maheswaran</forename><surname>Sathiamoorthy</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Yihua</forename><surname>Chen</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Rahul</forename><surname>Mazumder</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Lichan</forename><surname>Hong</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Ed</forename><surname>Chi</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j" coord="9,331.51,702.43,172.49,8.59;9,129.33,713.34,29.78,8.59">Advances in Neural Information Processing Systems</title>
		<imprint>
			<biblScope unit="volume">34</biblScope>
			<biblScope unit="page" from="29335" to="29347" />
			<date type="published" when="2021">2021</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="10,129.58,75.48,374.42,8.64;10,129.39,86.21,374.61,8.82;10,129.58,97.12,100.17,8.82" xml:id="b15">
	<analytic>
		<title level="a" type="main" coord="10,209.38,86.39,222.26,8.64">PixMix: Dreamlike Pictures Comprehensively Improve Safety Measures</title>
		<author>
			<persName coords=""><forename type="first">Dan</forename><surname>Hendrycks</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Andy</forename><surname>Zou</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Mantas</forename><surname>Mazeika</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Leonard</forename><surname>Tang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Bo</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Dawn</forename><surname>Song</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Jacob</forename><surname>Steinhardt</surname></persName>
		</author>
		<idno type="DOI">10.1109/cvpr52688.2022.01628</idno>
		<idno type="arXiv">arXiv:2009.03300</idno>
	</analytic>
	<monogr>
		<title level="m">2022 IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR)</title>
		<imprint>
			<publisher>IEEE</publisher>
			<date type="published" when="2020">2020</date>
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct coords="10,129.58,112.37,374.42,8.64;10,129.58,123.28,376.16,8.64;10,129.58,134.01,159.58,8.82" xml:id="b16">
	<analytic>
		<title level="a" type="main" coord="10,245.74,123.28,256.17,8.64">Natural Adversarial Examples</title>
		<author>
			<persName coords=""><forename type="first">Dan</forename><surname>Hendrycks</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Kevin</forename><surname>Zhao</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Steven</forename><surname>Basart</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Jacob</forename><surname>Steinhardt</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Dawn</forename><surname>Song</surname></persName>
		</author>
		<idno type="DOI">10.1109/cvpr46437.2021.01501</idno>
		<idno type="arXiv">arXiv:2103.03874</idno>
	</analytic>
	<monogr>
		<title level="m">2021 IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR)</title>
		<imprint>
			<publisher>IEEE</publisher>
			<date type="published" when="2021-06">2021</date>
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct coords="10,129.58,149.26,374.42,8.64;10,129.58,160.17,374.42,8.64;10,129.58,170.90,267.23,8.82" xml:id="b17">
	<analytic>
		<title/>
		<author>
			<persName coords=""><forename type="first">Alexandre</forename><surname>Albert Q Jiang</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Arthur</forename><surname>Sablayrolles</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Chris</forename><surname>Mensch</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Devendra</forename><surname>Bamford</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Diego</forename><surname>Singh Chaplot</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Florian</forename><surname>De Las Casas</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Gianna</forename><surname>Bressand</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Guillaume</forename><surname>Lengyel</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Lucile</forename><surname>Lample</surname></persName>
		</author>
		<author>
			<persName coords=""><surname>Saulnier</surname></persName>
		</author>
		<idno type="arXiv">arXiv:2310.06825</idno>
	</analytic>
	<monogr>
		<title level="j" coord="10,190.32,171.08,28.78,8.64">Mistral</title>
		<imprint>
			<biblScope unit="volume">7</biblScope>
			<date type="published" when="2023">2023</date>
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct coords="10,129.58,186.15,374.42,8.64;10,129.58,196.88,374.42,8.82;10,129.58,207.79,100.17,8.82" xml:id="b18">
	<analytic>
		<title level="a" type="main" coord="10,428.72,186.15,75.28,8.64;10,129.58,197.06,299.77,8.64">TriviaQA: A Large Scale Distantly Supervised Challenge Dataset for Reading Comprehension</title>
		<author>
			<persName coords=""><forename type="first">Mandar</forename><surname>Joshi</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Eunsol</forename><surname>Choi</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Daniel</forename><forename type="middle">S</forename><surname>Weld</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Luke</forename><surname>Zettlemoyer</surname></persName>
		</author>
		<idno type="DOI">10.18653/v1/p17-1147</idno>
		<idno type="arXiv">arXiv:1705.03551</idno>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 55th Annual Meeting of the Association for Computational Linguistics (Volume 1: Long Papers)</title>
		<meeting>the 55th Annual Meeting of the Association for Computational Linguistics (Volume 1: Long Papers)</meeting>
		<imprint>
			<publisher>Association for Computational Linguistics</publisher>
			<date type="published" when="2017">2017</date>
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct coords="10,129.58,223.04,374.42,8.64;10,129.22,233.95,374.77,8.64;10,129.58,244.68,374.42,8.82;10,129.30,255.59,136.16,8.82" xml:id="b19">
	<analytic>
		<title level="a" type="main" coord="10,425.52,233.95,78.48,8.64;10,129.58,244.85,169.05,8.64">Natural Questions: A Benchmark for Question Answering Research</title>
		<author>
			<persName coords=""><forename type="first">Tom</forename><surname>Kwiatkowski</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Jennimaria</forename><surname>Palomaki</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Olivia</forename><surname>Redfield</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Michael</forename><surname>Collins</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Ankur</forename><surname>Parikh</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Chris</forename><surname>Alberti</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Danielle</forename><surname>Epstein</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Illia</forename><surname>Polosukhin</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Jacob</forename><surname>Devlin</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Kenton</forename><surname>Lee</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Kristina</forename><surname>Toutanova</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Llion</forename><surname>Jones</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Matthew</forename><surname>Kelcey</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Ming-Wei</forename><surname>Chang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Andrew</forename><forename type="middle">M</forename><surname>Dai</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Jakob</forename><surname>Uszkoreit</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Quoc</forename><surname>Le</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Slav</forename><surname>Petrov</surname></persName>
		</author>
		<idno type="DOI">10.1162/tacl_a_00276</idno>
	</analytic>
	<monogr>
		<title level="j" coord="10,306.13,244.68,197.87,8.59;10,129.30,255.59,42.37,8.59">Transactions of the Association for Computational Linguistics</title>
		<title level="j" type="abbrev">Transactions of the Association for Computational Linguistics</title>
		<idno type="ISSNe">2307-387X</idno>
		<imprint>
			<biblScope unit="volume">7</biblScope>
			<biblScope unit="page" from="453" to="466" />
			<date type="published" when="2019-11">2019</date>
			<publisher>MIT Press - Journals</publisher>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="10,129.58,270.84,375.67,8.64;10,129.58,281.74,376.07,8.64;10,129.58,292.47,336.12,8.82" xml:id="b20">
	<monogr>
		<title level="m" type="main" coord="10,337.37,281.74,168.29,8.64;10,129.58,292.65,168.86,8.64">Gshard: Scaling giant models with conditional computation and automatic sharding</title>
		<author>
			<persName coords=""><forename type="first">Dmitry</forename><surname>Lepikhin</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Hyoukjoong</forename><surname>Lee</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Yuanzhong</forename><surname>Xu</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Dehao</forename><surname>Chen</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Orhan</forename><surname>Firat</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Yanping</forename><surname>Huang</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Maxim</forename><surname>Krikun</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Noam</forename><surname>Shazeer</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Zhifeng</forename><surname>Chen</surname></persName>
		</author>
		<idno type="arXiv">arXiv:2006.16668</idno>
		<imprint>
			<date type="published" when="2020">2020</date>
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct coords="10,129.58,307.73,374.42,8.64;10,129.58,318.46,375.67,8.82;10,129.58,329.54,22.42,8.64" xml:id="b21">
	<analytic>
		<title level="a" type="main" coord="10,394.55,307.73,109.45,8.64;10,129.58,318.63,234.56,8.64">Can a Suit of Armor Conduct Electricity? A New Dataset for Open Book Question Answering</title>
		<author>
			<persName coords=""><forename type="first">Todor</forename><surname>Mihaylov</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Peter</forename><surname>Clark</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Tushar</forename><surname>Khot</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Ashish</forename><surname>Sabharwal</surname></persName>
		</author>
		<idno type="DOI">10.18653/v1/d18-1260</idno>
		<idno type="arXiv">arXiv:1809.02789</idno>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 2018 Conference on Empirical Methods in Natural Language Processing</title>
		<meeting>the 2018 Conference on Empirical Methods in Natural Language Processing</meeting>
		<imprint>
			<publisher>Association for Computational Linguistics</publisher>
			<date type="published" when="2018">2018</date>
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct coords="10,129.58,344.62,374.42,8.64;10,129.58,355.35,257.51,8.82" xml:id="b22">
	<analytic>
		<title level="a" type="main" coord="10,299.91,344.62,204.09,8.64;10,129.58,355.52,90.28,8.64">Preprint repository arXiv achieves milestone million uploads</title>
		<author>
			<persName coords=""><forename type="first">Amirkeivan</forename><surname>Mohtashami</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Martin</forename><surname>Jaggi</surname></persName>
		</author>
		<idno type="DOI">10.1063/pt.5.028530</idno>
		<idno type="arXiv">arXiv:2305.16300</idno>
	</analytic>
	<monogr>
		<title level="j">Physics Today</title>
		<title level="j" type="abbrev">Phys. Today</title>
		<idno type="ISSNe">1945-0699</idno>
		<imprint>
			<date type="published" when="2023">2023</date>
			<publisher>AIP Publishing</publisher>
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct coords="10,129.58,370.60,376.07,8.64;10,129.58,381.51,374.42,8.64;10,129.58,392.24,206.60,8.82" xml:id="b23">
	<analytic>
		<title level="a" type="main" coord="10,312.90,381.51,191.10,8.64;10,129.58,392.41,39.09,8.64">BBQ: A hand-built bias benchmark for question answering</title>
		<author>
			<persName coords=""><forename type="first">Alicia</forename><surname>Parrish</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Angelica</forename><surname>Chen</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Nikita</forename><surname>Nangia</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Vishakh</forename><surname>Padmakumar</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Jason</forename><surname>Phang</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Jana</forename><surname>Thompson</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Phu</forename><forename type="middle">Mon</forename><surname>Htut</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Samuel</forename><surname>Bowman</surname></persName>
		</author>
		<idno type="DOI">10.18653/v1/2022.findings-acl.165</idno>
		<idno type="arXiv">arXiv:2110.08193</idno>
	</analytic>
	<monogr>
		<title level="m">Findings of the Association for Computational Linguistics: ACL 2022</title>
		<imprint>
			<publisher>Association for Computational Linguistics</publisher>
			<date type="published" when="2021">2021</date>
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct coords="10,129.58,407.49,374.42,8.64;10,129.58,418.40,376.17,8.64;10,129.58,429.13,159.58,8.82" xml:id="b24">
	<monogr>
		<title level="m" type="main" coord="10,187.26,418.40,313.98,8.64">Direct preference optimization: Your language model is secretly a reward model</title>
		<author>
			<persName coords=""><forename type="first">Rafael</forename><surname>Rafailov</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Archit</forename><surname>Sharma</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Eric</forename><surname>Mitchell</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Stefano</forename><surname>Ermon</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Christopher</forename><forename type="middle">D</forename><surname>Manning</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Chelsea</forename><surname>Finn</surname></persName>
		</author>
		<idno type="arXiv">arXiv:2305.18290</idno>
		<imprint>
			<date type="published" when="2023">2023</date>
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct coords="10,129.58,444.38,374.42,8.64;10,129.58,455.11,375.66,8.82;10,129.58,466.19,22.42,8.64" xml:id="b25">
	<analytic>
		<title level="a" type="main" coord="10,436.17,444.38,67.83,8.64;10,129.58,455.29,188.89,8.64">WinoGrande</title>
		<author>
			<persName coords=""><forename type="first">Keisuke</forename><surname>Sakaguchi</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Ronan</forename><forename type="middle">Le</forename><surname>Bras</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Chandra</forename><surname>Bhagavatula</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Yejin</forename><surname>Choi</surname></persName>
		</author>
		<idno type="DOI">10.1145/3474381</idno>
	</analytic>
	<monogr>
		<title level="j" coord="10,325.79,455.11,113.14,8.59">Communications of the ACM</title>
		<title level="j" type="abbrev">Commun. ACM</title>
		<idno type="ISSN">0001-0782</idno>
		<idno type="ISSNe">1557-7317</idno>
		<imprint>
			<biblScope unit="volume">64</biblScope>
			<biblScope unit="issue">9</biblScope>
			<biblScope unit="page" from="99" to="106" />
			<date type="published" when="2021-08-24">2021</date>
			<publisher>Association for Computing Machinery (ACM)</publisher>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="10,129.58,481.27,376.07,8.64;10,129.58,492.00,345.51,8.82" xml:id="b26">
	<analytic>
		<title level="a" type="main" coord="10,439.52,481.27,66.13,8.64;10,129.58,492.18,178.58,8.64">Social IQa: Commonsense Reasoning about Social Interactions</title>
		<author>
			<persName coords=""><forename type="first">Maarten</forename><surname>Sap</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Hannah</forename><surname>Rashkin</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Derek</forename><surname>Chen</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Ronan</forename><surname>Le Bras</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Yejin</forename><surname>Choi</surname></persName>
		</author>
		<idno type="DOI">10.18653/v1/d19-1454</idno>
		<idno type="arXiv">arXiv:1904.09728</idno>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 2019 Conference on Empirical Methods in Natural Language Processing and the 9th International Joint Conference on Natural Language Processing (EMNLP-IJCNLP)</title>
		<meeting>the 2019 Conference on Empirical Methods in Natural Language Processing and the 9th International Joint Conference on Natural Language Processing (EMNLP-IJCNLP)</meeting>
		<imprint>
			<publisher>Association for Computational Linguistics</publisher>
			<date type="published" when="2019">2019</date>
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct coords="10,129.58,507.25,375.67,8.64;10,129.58,518.16,374.42,8.64;10,129.58,528.89,185.02,8.82" xml:id="b27">
	<monogr>
		<author>
			<persName coords=""><forename type="first">Noam</forename><surname>Shazeer</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Azalia</forename><surname>Mirhoseini</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Krzysztof</forename><surname>Maziarz</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Andy</forename><surname>Davis</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Quoc</forename><surname>Le</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Geoffrey</forename><surname>Hinton</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Jeff</forename><surname>Dean</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1701.06538</idno>
		<title level="m" coord="10,194.31,518.16,309.69,8.64;10,129.58,529.07,18.21,8.64">Outrageously large neural networks: The sparsely-gated mixture-of-experts layer</title>
		<imprint>
			<date type="published" when="2017">2017</date>
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct coords="10,129.58,544.14,374.42,8.64;10,129.58,555.05,376.16,8.64;10,129.58,565.78,374.42,8.82;10,129.58,576.68,100.17,8.82" xml:id="b28">
	<analytic>
		<title level="a" type="main" coord="10,129.58,565.95,305.39,8.64">Challenging BIG-Bench Tasks and Whether Chain-of-Thought Can Solve Them</title>
		<author>
			<persName coords=""><forename type="first">Mirac</forename><surname>Suzgun</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Nathan</forename><surname>Scales</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Nathanael</forename><surname>Schärli</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Sebastian</forename><surname>Gehrmann</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Yi</forename><surname>Tay</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Hyung</forename><forename type="middle">Won</forename><surname>Chung</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Aakanksha</forename><surname>Chowdhery</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Quoc</forename><surname>Le</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Ed</forename><surname>Chi</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Denny</forename><surname>Zhou</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Jason</forename><surname>Wei</surname></persName>
		</author>
		<idno type="DOI">10.18653/v1/2023.findings-acl.824</idno>
		<idno type="arXiv">arXiv:2210.09261</idno>
	</analytic>
	<monogr>
		<title level="m">Findings of the Association for Computational Linguistics: ACL 2023</title>
		<imprint>
			<publisher>Association for Computational Linguistics</publisher>
			<date type="published" when="2022">2022</date>
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct coords="10,129.58,591.94,376.07,8.64;10,129.58,602.67,375.67,8.82;10,129.58,613.75,22.42,8.64" xml:id="b29">
	<analytic>
		<title level="a" type="main" coord="10,403.04,591.94,102.61,8.64;10,129.58,602.84,235.53,8.64"></title>
		<author>
			<persName coords=""><forename type="first">Alon</forename><surname>Talmor</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Jonathan</forename><surname>Herzig</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Nicholas</forename><surname>Lourie</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Jonathan</forename><surname>Berant</surname></persName>
		</author>
		<idno type="DOI">10.18653/v1/n19-1421</idno>
		<idno type="arXiv">arXiv:1811.00937</idno>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 2019 Conference of the North</title>
		<meeting>the 2019 Conference of the North</meeting>
		<imprint>
			<publisher>Association for Computational Linguistics</publisher>
			<date type="published" when="2018">2018</date>
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct coords="10,129.58,628.83,375.66,8.64;10,129.58,639.56,374.42,8.82;10,129.58,650.46,117.99,8.82" xml:id="b30">
	<analytic>
		<title level="a" type="main" coord="10,276.15,639.73,95.16,8.64">Attention is all you need</title>
		<author>
			<persName coords=""><forename type="first">Ashish</forename><surname>Vaswani</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Noam</forename><surname>Shazeer</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Niki</forename><surname>Parmar</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Jakob</forename><surname>Uszkoreit</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Llion</forename><surname>Jones</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Aidan</forename><forename type="middle">N</forename><surname>Gomez</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Łukasz</forename><surname>Kaiser</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Illia</forename><surname>Polosukhin</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j" coord="10,379.11,639.56,124.89,8.59;10,129.58,650.46,74.02,8.59">Advances in neural information processing systems</title>
		<imprint>
			<biblScope unit="volume">30</biblScope>
			<date type="published" when="2017">2017</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="10,129.58,665.72,374.42,8.64;10,129.58,676.45,309.30,8.82" xml:id="b31">
	<analytic>
		<title level="a" type="main">HellaSwag: Can a Machine Really Finish Your Sentence?</title>
		<author>
			<persName coords=""><forename type="first">Rowan</forename><surname>Zellers</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Ari</forename><surname>Holtzman</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Yonatan</forename><surname>Bisk</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Ali</forename><surname>Farhadi</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Yejin</forename><surname>Choi</surname></persName>
		</author>
		<idno type="DOI">10.18653/v1/p19-1472</idno>
		<idno type="arXiv">arXiv:1905.07830</idno>
	</analytic>
	<monogr>
		<title level="m" coord="10,432.12,665.72,71.88,8.64;10,129.58,676.62,145.53,8.64">Proceedings of the 57th Annual Meeting of the Association for Computational Linguistics</title>
		<meeting>the 57th Annual Meeting of the Association for Computational Linguistics</meeting>
		<imprint>
			<publisher>Association for Computational Linguistics</publisher>
			<date type="published" when="2019">2019</date>
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct coords="10,129.58,691.70,375.66,8.64;10,129.58,702.61,374.42,8.64;10,129.58,713.34,219.05,8.82" xml:id="b32">
	<monogr>
		<author>
			<persName coords=""><forename type="first">Lianmin</forename><surname>Zheng</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Wei-Lin</forename><surname>Chiang</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Ying</forename><surname>Sheng</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Siyuan</forename><surname>Zhuang</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Zhanghao</forename><surname>Wu</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Yonghao</forename><surname>Zhuang</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Zi</forename><surname>Lin</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Zhuohan</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Dacheng</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Eric</forename><surname>Xing</surname></persName>
		</author>
		<idno type="arXiv">arXiv:2306.05685</idno>
		<title level="m" coord="10,332.55,702.61,171.45,8.64;10,129.58,713.51,51.87,8.64">Judging llm-as-a-judge with mt-bench and chatbot arena</title>
		<imprint>
			<date type="published" when="2023">2023</date>
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct coords="11,129.58,75.48,375.67,8.64;11,129.11,86.39,374.89,8.64;11,129.58,97.12,194.44,8.82" xml:id="b33">
	<monogr>
		<title level="m" type="main" coord="11,250.97,86.39,253.03,8.64;11,129.58,97.30,26.81,8.64">Agieval: A human-centric benchmark for evaluating foundation models</title>
		<author>
			<persName coords=""><forename type="first">Wanjun</forename><surname>Zhong</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Ruixiang</forename><surname>Cui</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Yiduo</forename><surname>Guo</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Yaobo</forename><surname>Liang</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Shuai</forename><surname>Lu</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Yanlin</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Amin</forename><surname>Saied</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Weizhu</forename><surname>Chen</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Nan</forename><surname>Duan</surname></persName>
		</author>
		<idno type="arXiv">arXiv:2304.06364</idno>
		<imprint>
			<date type="published" when="2023">2023</date>
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct coords="11,129.58,112.19,375.66,8.64;11,129.58,122.92,374.42,8.82;11,129.25,133.83,247.91,8.82" xml:id="b34">
	<analytic>
		<title level="a" type="main" coord="11,264.91,123.10,182.80,8.64">Mixture-of-experts with expert choice routing</title>
		<author>
			<persName coords=""><forename type="first">Yanqi</forename><surname>Zhou</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Tao</forename><surname>Lei</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Hanxiao</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Nan</forename><surname>Du</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Yanping</forename><surname>Huang</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Vincent</forename><surname>Zhao</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Andrew</forename><forename type="middle">M</forename><surname>Dai</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">V</forename><surname>Quoc</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">James</forename><surname>Le</surname></persName>
		</author>
		<author>
			<persName coords=""><surname>Laudon</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j" coord="11,455.22,122.92,48.77,8.59;11,129.25,133.83,156.20,8.59">Advances in Neural Information Processing Systems</title>
		<imprint>
			<biblScope unit="volume">35</biblScope>
			<biblScope unit="page" from="7103" to="7114" />
			<date type="published" when="2022">2022</date>
		</imprint>
	</monogr>
</biblStruct>

				</listBibl>
			</div>
		</back>
	</text>
</TEI>
